{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc696eda",
   "metadata": {},
   "source": [
    "# **Return of the Schema** for *ARCO Italian Cultural Heritage*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1f207",
   "metadata": {},
   "source": [
    "## Path Definition Basic Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df68574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, RDFS, OWL, Namespace\n",
    "from urllib.parse import quote\n",
    "from rdflib.namespace import split_uri\n",
    "from rdflib.term import URIRef\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "\n",
    "def serialize(graph, path):\n",
    "    graph.serialize(path.with_suffix(\".xml\"), format=\"xml\")\n",
    "    !/home/navis/robot/robot merge --input {path.with_suffix(\".xml\")} --output {path.with_suffix(\".owl\")}\n",
    "    path.with_suffix(\".xml\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7e8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATERIALIZE = True\n",
    "VERSION = 5\n",
    "DATASET_NAME = f\"ARCO-{str(VERSION)}\"\n",
    "DATASET_NAME += f\"-{'MATERIALIZE' if MATERIALIZE else \"BASE\"}\"\n",
    "BASE_FILENAME = f\"filtered{VERSION}_triples.txt\"\n",
    "CA_FILENAME = f\"class_assertions_filtered{VERSION}.json\"\n",
    "\n",
    "home_path = Path().cwd().absolute().parent.parent \n",
    "dataset_path = home_path / \"kgsaf_data\" / f\"{'materialize' if MATERIALIZE else \"base\"}\" / \"unpack\" / DATASET_NAME\n",
    "arco_path = home_path / \"kgsaf_data\" / \"ontologies\"/ \"unpack\" / \"ARCO-2025\"\n",
    "arco_triples_file = arco_path / \"ARCO_ABOX\" / BASE_FILENAME\n",
    "arco_ca_file = arco_path / \"ARCO_ABOX\" / CA_FILENAME\n",
    "\n",
    "print(\"Base Path\", home_path)\n",
    "print(\"Ontology\", arco_path)\n",
    "print(\"Dataset\", dataset_path)\n",
    "print(\"CA\", arco_ca_file)\n",
    "print(\"TRIPLE\", arco_triples_file)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "if MATERIALIZE:\n",
    "    print(\"MATERIALIZED Ontology\")\n",
    "    onto_file = arco_path / \"arco_merged_repaired_materialized.owl\"\n",
    "else:\n",
    "    print(\"BASE Ontology\")\n",
    "    onto_file = arco_path / \"arco_merged_repaired.owl\"\n",
    "\n",
    "print(\"Loading Ontology\")\n",
    "\n",
    "arco_ontology = Graph()\n",
    "arco_ontology.parse(onto_file, format=\"xml\")\n",
    "\n",
    "print(\"Ontology Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5de81b",
   "metadata": {},
   "source": [
    "# Triple Cleaning and Splitting, Deprecated Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(arco_triples_file, \"r\") as in_f, open(arco_path / \"ARCO_ABOX\" / f\"filtered{version}_removed.txt\", \"w\") as out_f, open(arco_path / \"removed_uris.txt\", \"r\" ) as rem_f:\n",
    "    r_list = {s.strip(\"\\n\") for s in rem_f.readlines()}\n",
    "   \n",
    "    for line in in_f.readlines():\n",
    "        sline = line.strip().split(\"\\t\")\n",
    "        s = sline[0]\n",
    "        p = sline[1]\n",
    "        o = sline[2]\n",
    "        if (p in r_list) or (o in r_list) or (s in r_list) or (URIRef(s), RDF.type, OWL.Class) in arco_ontology or (URIRef(o), RDF.type, OWL.Class) in arco_ontology:\n",
    "            print(f\"Removed {s,p,o}\")\n",
    "        else:\n",
    "            out_f.write(f\"{s}\\t{p}\\t{o}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b138869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples.splitting import CoverageSplitter\n",
    "import numpy as np\n",
    "from rdflib import Graph, OWL, Literal\n",
    "from rdflib.namespace import XSD    \n",
    "\n",
    "triples = TriplesFactory.from_path(arco_path / \"ARCO_ABOX\" / f\"filtered{version}_removed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_obj_props = {str(s) for s in set(arco_ontology.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI }\n",
    "\n",
    "print(len(real_obj_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd97092",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_props = set(triples.relation_id_to_label.values())\n",
    "print(len(obj_props))\n",
    "print(obj_props)\n",
    "\n",
    "reals = real_obj_props & obj_props\n",
    "\n",
    "print(len(reals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0aa3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples.splitting import CoverageSplitter\n",
    "import numpy as np\n",
    "\n",
    "MIN_TRIPLES_RELATION = int(VERSION)\n",
    "\n",
    "\n",
    "rels, counts = np.unique(triples.mapped_triples[:, 1], return_counts=True)\n",
    "rel_counts = dict(zip(rels, counts))\n",
    "\n",
    "keep_relations = [r for r, c in rel_counts.items() if c >= MIN_TRIPLES_RELATION]\n",
    "\n",
    "triples_clean = triples.new_with_restriction(\n",
    "    relations=keep_relations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original triples:\", triples.num_triples)\n",
    "print(\"Cleaned triples:\", triples_clean.num_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mappings = {v:k for k,v in triples_clean.entity_id_to_label.items()}\n",
    "relation_mappings = {v:k for k,v in triples_clean.relation_id_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a68d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = triples_clean.split(\n",
    "    ratios=[0.7, 0.1, 0.2],\n",
    "    random_state=42,\n",
    "    method=CoverageSplitter(),      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=train.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "valid_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=valid.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "test_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=test.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da3b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_clean)\n",
    "print(test_clean)\n",
    "print(valid_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples.leakage import unleak\n",
    "\n",
    "train_unleak, valid_unleak, test_unleak = unleak(\n",
    "    train_clean,\n",
    "    *[valid_clean, test_clean],\n",
    "    n=None,\n",
    "    minimum_frequency=0.97\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fee317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_unleak)\n",
    "print(test_unleak)\n",
    "print(valid_unleak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2495b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_path / \"abox\" / \"splits\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "targets = [\n",
    "    (dataset_path / \"abox/splits/train\", train_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/valid\", valid_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/test\", test_unleak.triples)\n",
    "]\n",
    "\n",
    "\n",
    "for path, split in targets:\n",
    "    out_graph = Graph()\n",
    "    for triple in split:\n",
    "        s = URIRef(triple[0].strip())\n",
    "        p = URIRef(triple[1].strip())\n",
    "        o = URIRef(triple[2].strip())\n",
    "        out_graph.add((URIRef(s), URIRef(p), URIRef(o)))\n",
    "\n",
    "    out_graph.serialize(path.with_suffix(\".nt\"), format=\"nt\")\n",
    "\n",
    "!cat {dataset_path}/abox/splits/*.nt > {dataset_path}/abox/triples.nt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741220b6",
   "metadata": {},
   "source": [
    "# ABOX Individuals and Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "individuals = set(data_triples.subjects()) | set(data_triples.objects())\n",
    "\n",
    "print(\"Len Individuals\", len(individuals))\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec37c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    out_graph.add((ind, RDF.type, OWL.NamedIndividual))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"individuals\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860c482",
   "metadata": {},
   "source": [
    "### [BASE] RDF Lib Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa8668",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "with open(arco_ca_file, \"r\") as ca_file:\n",
    "    ca_data = json.load(ca_file)\n",
    "    for key in ca_data.keys():\n",
    "        ind = URIRef(key.strip())\n",
    "        for c in ca_data[key]:\n",
    "            cls = URIRef(c.strip())\n",
    "            if (cls, RDF.type, OWL.Class) in arco_ontology:\n",
    "                out_graph.add((ind, RDF.type, cls))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a993a",
   "metadata": {},
   "source": [
    "### [REASONED] Intermediate Reasoning File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59373914",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "with open(arco_ca_file, \"r\") as ca_file:\n",
    "    ca_data = json.load(ca_file)\n",
    "    for key in ca_data.keys():\n",
    "        ind = URIRef(key.strip())\n",
    "        for c in ca_data[key]:\n",
    "            cls = URIRef(c.strip())\n",
    "            if (cls, RDF.type, OWL.Class) in arco_ontology:\n",
    "                out_graph.add((ind, RDF.type, cls))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"unreasoned_class_assertions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5309386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onto_file)\n",
    "!java -Xmx16G -jar /home/navis/robot/robot.jar merge -vvv \\\n",
    "    --input {dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\"} \\\n",
    "    --input {dataset_path / \"abox\" / \"individuals.owl\"} \\\n",
    "    --input {dataset_path / \"abox\" / \"triples.nt\"} \\\n",
    "    --input {onto_file} \\\n",
    "    --output {dataset_path / \"abox\" / \"arco_10_intermediate_abox_tbox.owl\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb0baa",
   "metadata": {},
   "source": [
    "### [REASONED] Server Reasoned Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bdcdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Reasoned Class Assertions from \", arco_path / \"ARCO_CA\" / f\"arco_intermediate_abox_tbox_ca_materialized.owl\" )\n",
    "ca_graph = Graph()\n",
    "ca_graph.parse(arco_path / \"ARCO_CA\" / f\"arco_intermediate_abox_tbox_ca_materialized.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abe055",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    for o in set(ca_graph.objects(ind, RDF.type)) - BUILTIN_URI:\n",
    "        out_graph.add((ind,RDF.type, o))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6959a9",
   "metadata": {},
   "source": [
    "# RBOX Roles Definition and Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "class_assertions = Graph()\n",
    "class_assertions.parse(dataset_path / \"abox\" / \"class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611274f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_obj_props = set(data_triples.predicates())\n",
    "print(\"Seed Object Properties\", len(seed_obj_props))\n",
    "\n",
    "seed_classes =  set(class_assertions.subjects(RDF.type, OWL.Class))\n",
    "print(\"Seed Classes\", len(seed_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6970f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, BNode, RDF, RDFS, OWL\n",
    "\n",
    "BUILTIN_URI = {\n",
    "    URIRef(\"http://schema.org/Thing\"),\n",
    "    OWL.Thing,\n",
    "    OWL.Nothing,\n",
    "    OWL.NamedIndividual,\n",
    "    OWL.Class,\n",
    "    OWL.topObjectProperty,\n",
    "    OWL.bottomObjectProperty,\n",
    "    RDF.type,\n",
    "    RDFS.domain,\n",
    "    RDFS.range,\n",
    "    OWL.ObjectProperty,\n",
    "    OWL.Restriction,\n",
    "    OWL.DatatypeProperty,\n",
    "    RDFS.Literal\n",
    "}\n",
    "\n",
    "removal = [\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasDerivedFrom\"),\n",
    "    RDFS.isDefinedBy,\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasInfluencedBy\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def extract_recursive_description(graph: Graph, elements: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = set(elements)\n",
    "    processed = set()\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "        \n",
    "    return extracted_graph\n",
    "\n",
    "out_graph = extract_recursive_description(arco_ontology, seed_classes | seed_obj_props)\n",
    "\n",
    "serialize(out_graph, dataset_path / \"ontology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import BNode\n",
    "\n",
    "onto_graph = Graph()\n",
    "onto_graph.parse(dataset_path / \"ontology.owl\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_description(graph: Graph, elem: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = {elem}\n",
    "    processed = set()\n",
    "\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.Class))\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.ObjectProperty))\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.DatatypeProperty))\n",
    "\n",
    "    return extracted_graph\n",
    "\n",
    "\n",
    "rbox_graph = Graph()\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.DatatypeProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "(dataset_path / \"rbox\").mkdir(exist_ok=True)\n",
    "\n",
    "serialize(rbox_graph, dataset_path / \"rbox\" / \"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e00c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_graph = Graph()\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    for s,p,o in onto_graph.triples((c, None, None)):\n",
    "        if p == RDFS.subClassOf:\n",
    "            taxonomy_graph.add((s,p,o))\n",
    "            if isinstance(o, BNode):\n",
    "                taxonomy_graph += extract_description(onto_graph, o)\n",
    "\n",
    "(dataset_path / \"tbox\").mkdir(exist_ok=True)\n",
    "serialize(taxonomy_graph, dataset_path / \"tbox\" / \"taxonomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf7964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_graph = Graph()\n",
    "\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    if not isinstance(c, BNode):\n",
    "        for s,p,o in onto_graph.triples((c, None, None)):\n",
    "            if p != RDFS.subClassOf:\n",
    "                \n",
    "                schema_graph.add((s,p,o))\n",
    "\n",
    "                for elem in onto_graph.objects(o, RDF.type):\n",
    "                    schema_graph.add((o, RDF.type, elem))\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    print(f\"Found BNODE in Triple {s, p, o}\")\n",
    "                    schema_graph += extract_description(onto_graph, o)\n",
    "            \n",
    "\n",
    "serialize(schema_graph, dataset_path / \"tbox\" / \"schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03922d4f",
   "metadata": {},
   "source": [
    "# Final Ontology and Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/navis/robot/robot merge \\\n",
    "--input  {dataset_path / \"ontology.owl\"} \\\n",
    "--input  {dataset_path / \"abox\" / \"individuals.owl\"} \\\n",
    "--input {dataset_path / \"abox\" / \"triples.nt\"} \\\n",
    "--input {dataset_path / \"abox\" / \"class_assertions.owl\"} \\\n",
    "--output {dataset_path / \"knowledge_graph.owl\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
