{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc696eda",
   "metadata": {},
   "source": [
    "# **Return of the Schema** for *YAGO3*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1f207",
   "metadata": {},
   "source": [
    "## Path Definition Basic Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c12a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, RDFS, OWL, Namespace\n",
    "from urllib.parse import quote\n",
    "from rdflib.namespace import split_uri\n",
    "from rdflib.term import URIRef\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "\n",
    "def serialize(graph, path):\n",
    "    graph.serialize(path.with_suffix(\".xml\"), format=\"xml\")\n",
    "    !/home/navis/robot/robot merge --input {path.with_suffix(\".xml\")} --output {path.with_suffix(\".owl\")}\n",
    "    path.with_suffix(\".xml\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb0570",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATERIALIZE = True\n",
    "YAGO_IRI = \"http://yago-knowledge.org/resource/\"\n",
    "DBPEDIA_RESOURCE = \"http://dbpedia.org/resource/\"\n",
    "DBPEDIA_ONTOLOGY = \"http://dbpedia.org/ontology/\"\n",
    "DATASET_NAME = \"YAGO3-10-C\"\n",
    "DATASET_NAME += f\"-{'MATERIALIZE' if MATERIALIZE else \"BASE\"}\"\n",
    "\n",
    "home_path = Path().cwd().absolute().parent.parent \n",
    "dataset_path = home_path / \"kgsaf_data\" / f\"{'materialize' if MATERIALIZE else \"base\"}\" / \"unpack\" / DATASET_NAME\n",
    "onto_path = home_path / \"kgsaf_data\" / \"ontologies\"/ \"unpack\" / \"YAGO3\"\n",
    "\n",
    "print(\"Base Path\", home_path)\n",
    "print(\"Ontology\", onto_path)\n",
    "print(\"Dataset\", dataset_path)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "if MATERIALIZE:\n",
    "    print(\"MATERIALIZED Ontology\")\n",
    "    onto_tbox_file = onto_path / \"yago3_tbox_materialized.owl\"\n",
    "    onto_rbox_file = onto_path / \"yago3_rbox_materialized.owl\"\n",
    "else:\n",
    "    print(\"BASE Ontology\")\n",
    "    onto_tbox_file = onto_path / \"yago3_tbox.owl\"\n",
    "    onto_rbox_file = onto_path / \"yago3_rbox.owl\"\n",
    "\n",
    "print(\"Loading Ontology\")\n",
    "\n",
    "yago_ontology = Graph()\n",
    "yago_ontology.parse(onto_rbox_file, format=\"xml\")\n",
    "yago_ontology.parse(onto_tbox_file, format=\"xml\")\n",
    "\n",
    "print(\"Ontology Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03536b2a",
   "metadata": {},
   "source": [
    "# [O] ABOX Triple Analysis and Cleaning\n",
    "\n",
    "Removal of triples with individuals that are also classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbe278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "individuals = set(data_triples.subjects()) | set(data_triples.objects())\n",
    "\n",
    "print(\"Len Individuals\", len(individuals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_classes = set()\n",
    "\n",
    "for ind in individuals:\n",
    "    if (ind, RDF.type, OWL.Class) in yago_ontology:\n",
    "        ind_classes.add(ind)\n",
    "\n",
    "print(\"Individuals that are Classes:\", len(ind_classes), ind_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = set(data_triples.predicates())\n",
    "\n",
    "print(\"Predicates\", len(preds))\n",
    "\n",
    "for p in preds:\n",
    "    if (p, RDF.type, OWL.DatatypeProperty) in yago_ontology:\n",
    "        print(\"This property is incorreclty defined as DATAPROP\", p)\n",
    "\n",
    "    if (p, RDF.type, OWL.ObjectProperty) not  in yago_ontology:\n",
    "        print(\"Missing OBJPROP definition\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a713bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [\n",
    "    dataset_path / \"abox\" / \"splits\"/ \"train.nt\",\n",
    "    dataset_path / \"abox\" / \"splits\"/ \"test.nt\",\n",
    "    dataset_path / \"abox\" /  \"triples.nt\",\n",
    "    dataset_path / \"abox\" / \"splits\"/ \"valid.nt\"\n",
    "]:\n",
    "    out_graph = Graph()\n",
    "    out_graph.parse(file)\n",
    "\n",
    "    new_file = file.with_name(file.stem + '_legacy' + file.suffix)\n",
    "    file.rename(new_file)\n",
    "\n",
    "    for s,p,o in out_graph.triples((None, None, None)):\n",
    "        if (s in ind_classes) or (o in ind_classes):\n",
    "            out_graph.remove((s,p,o))\n",
    "    \n",
    "    out_graph.serialize(file.with_name(file.stem + \"_cleaned\" + file.suffix), format=\"nt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "del individuals\n",
    "del out_graph\n",
    "del ind_classes\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb74bee",
   "metadata": {},
   "source": [
    "# [O] Machine Learning Ready Compatibility Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac54e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [\n",
    "    dataset_path / \"abox\" / \"splits\"/ \"train_cleaned.nt\",\n",
    "    dataset_path / \"abox\" / \"splits\"/ \"test_cleaned.nt\",\n",
    "    dataset_path / \"abox\" / \"splits\"/ \"valid_cleaned.nt\"\n",
    "]:\n",
    "    \n",
    "    with open(file.with_suffix(\".tsv\"),\"w\") as tsv_out:\n",
    "        graph = Graph()\n",
    "        graph.parse(file)\n",
    "\n",
    "        for s,p,o in graph:\n",
    "            tsv_out.write(f\"{str(s)}\\t{str(p)}\\t{str(o)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ef8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "import numpy as np\n",
    "\n",
    "train_path = dataset_path / \"abox\" / \"splits\" / \"train_cleaned.tsv\"\n",
    "valid_path = dataset_path / \"abox\" / \"splits\" / \"valid_cleaned.tsv\"\n",
    "test_path  = dataset_path / \"abox\" / \"splits\" / \"test_cleaned.tsv\"\n",
    "\n",
    "train = TriplesFactory.from_path(train_path)\n",
    "\n",
    "valid = TriplesFactory.from_path(\n",
    "    valid_path,\n",
    "    entity_to_id=train.entity_to_id,\n",
    "    relation_to_id=train.relation_to_id,\n",
    ")\n",
    "test = TriplesFactory.from_path(\n",
    "    test_path,\n",
    "    entity_to_id=train.entity_to_id,\n",
    "    relation_to_id=train.relation_to_id,\n",
    ")\n",
    "\n",
    "print(train)\n",
    "print(test)\n",
    "print(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fdb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples.leakage import unleak\n",
    "\n",
    "train_unleak, valid_unleak, test_unleak = unleak(\n",
    "    train,\n",
    "    *[valid, test],\n",
    "    n=None,\n",
    "    minimum_frequency=0.97\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ebee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_unleak)\n",
    "print(test_unleak)\n",
    "print(valid_unleak)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    (dataset_path / \"abox/splits/train\", train_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/valid\", valid_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/test\", test_unleak.triples)\n",
    "]\n",
    "\n",
    "\n",
    "for path, split in targets:\n",
    "    out_graph = Graph()\n",
    "    for triple in split:\n",
    "        s = URIRef(triple[0])\n",
    "        p = URIRef(triple[1])\n",
    "        o = URIRef(triple[2])\n",
    "        out_graph.add((URIRef(s), URIRef(p), URIRef(o)))\n",
    "\n",
    "    out_graph.serialize(path.with_suffix(\".nt\"), format=\"nt\")\n",
    "\n",
    "!cat {dataset_path}/abox/splits/*.nt > {dataset_path}/abox/triples.nt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741220b6",
   "metadata": {},
   "source": [
    "# [R] ABOX Individuals and Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "individuals = set(data_triples.subjects()) | set(data_triples.objects())\n",
    "\n",
    "print(\"Len Individuals\", len(individuals))\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec37c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    out_graph.add((ind, RDF.type, OWL.NamedIndividual))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"individuals\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7411e807",
   "metadata": {},
   "source": [
    "### [BASE] RDF Lib Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "with open(onto_path / \"yagoTypes.tsv\", \"r\") as yt_f:\n",
    "    for line in yt_f.readlines()[1:]:\n",
    "        sline = line.strip().split()[1:]\n",
    "        s = URIRef(YAGO_IRI + quote(sline[0].strip(\"<>\")))\n",
    "        c = URIRef(YAGO_IRI + quote(sline[2].strip(\"<>\")))\n",
    "\n",
    "        if s in individuals:\n",
    "            if (c, RDF.type, OWL.Class) in yago_ontology:\n",
    "                out_graph.add((s, RDF.type, c))\n",
    "                if REASONED:\n",
    "                    for sup_c in set(yago_ontology.objects(c, RDFS.subClassOf)) - BUILTIN_URI:\n",
    "                        out_graph.add((s, RDF.type, sup_c))\n",
    "            else:\n",
    "                print(f\"Not a class {c}\")\n",
    "            \n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31a0af",
   "metadata": {},
   "source": [
    "### [MATERIALIZED] Reasoner Class Assertions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "with open(onto_path / \"yagoTypes.tsv\", \"r\") as yt_f:\n",
    "    for line in yt_f.readlines()[1:]:\n",
    "        sline = line.strip().split()[1:]\n",
    "        s = URIRef(YAGO_IRI + quote(sline[0].strip(\"<>\")))\n",
    "        c = URIRef(YAGO_IRI + quote(sline[2].strip(\"<>\")))\n",
    "\n",
    "        if s in individuals:\n",
    "            out_graph.add((s, RDF.type, c))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"unreasoned_class_assertions\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df005ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -Xmx16G -jar /home/navis/robot/robot.jar merge -vvv \\\n",
    "    --input {dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\"} \\\n",
    "    --input {yago3_path / \"yago3ClassReasoned.owl\"} \\\n",
    "    --output {dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\"}\n",
    "\n",
    "\n",
    "!java -Xmx16G -jar /home/navis/robot/robot.jar reason -vvv \\\n",
    "  --reasoner ELK \\\n",
    "  --create-new-ontology true \\\n",
    "  --input {dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\"} \\\n",
    "  --output {dataset_path / \"abox\" / \"inferred_class_assertions.owl\"} \\\n",
    "  --axiom-generators \"ClassAssertion\" \\\n",
    "  --remove-redundant-subclass-axioms false \\\n",
    "  --exclude-tautologies structural \\\n",
    "  --include-indirect true \\\n",
    "  -D {dataset_path / \"class_assertions_debug.owl\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = Graph()\n",
    "ca.parse(dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\")\n",
    "ca.parse(dataset_path / \"abox\" / \"inferred_class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for s,p,o in ca.triples((None, RDF.type, None)):\n",
    "    if s in individuals:\n",
    "        out_graph.add((s,p,o))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_path / \"abox\" / \"inferred_class_assertions.owl\").unlink()\n",
    "(dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\").unlink()\n",
    "(dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab44efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(out_graph)\n",
    "del(ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6959a9",
   "metadata": {},
   "source": [
    "# Schema Extraction and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "class_assertions = Graph()\n",
    "class_assertions.parse(dataset_path / \"abox\" / \"class_assertions.owl\")\n",
    "\n",
    "seed_obj_props = set(data_triples.predicates())\n",
    "print(\"Seed Object Properties\", len(seed_obj_props))\n",
    "\n",
    "seed_classes =  set(class_assertions.subjects(RDF.type, OWL.Class))\n",
    "print(\"Seed Classes\", len(seed_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7bdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, BNode, RDF, RDFS, OWL\n",
    "\n",
    "BUILTIN_URI = {\n",
    "    URIRef(\"http://schema.org/Thing\"),\n",
    "    OWL.Thing,\n",
    "    OWL.Nothing,\n",
    "    OWL.NamedIndividual,\n",
    "    OWL.Class,\n",
    "    OWL.topObjectProperty,\n",
    "    OWL.bottomObjectProperty,\n",
    "    RDF.type,\n",
    "    RDFS.domain,\n",
    "    RDFS.range,\n",
    "    OWL.ObjectProperty,\n",
    "    OWL.Restriction,\n",
    "    OWL.DatatypeProperty,\n",
    "    RDFS.Literal,\n",
    "    RDF.Property,\n",
    "    OWL.FunctionalProperty,\n",
    "    OWL.TransitiveProperty,\n",
    "    OWL.ReflexiveProperty,\n",
    "    OWL.IrreflexiveProperty,\n",
    "    OWL.InverseFunctionalProperty,\n",
    "    OWL.AsymmetricProperty,\n",
    "    OWL.SymmetricProperty,\n",
    "}\n",
    "\n",
    "removal = [\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasDerivedFrom\"),\n",
    "    RDFS.isDefinedBy,\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasInfluencedBy\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def extract_recursive_description(graph: Graph, elements: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = set(elements)\n",
    "    processed = set()\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "        \n",
    "    return extracted_graph\n",
    "\n",
    "out_graph = extract_recursive_description(yago_ontology, seed_classes | seed_obj_props)\n",
    "\n",
    "serialize(out_graph, dataset_path / \"ontology\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6970f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import BNode\n",
    "\n",
    "onto_graph = Graph()\n",
    "onto_graph.parse(dataset_path / \"ontology.owl\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_description(graph: Graph, elem: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = {elem}\n",
    "    processed = set()\n",
    "\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.Class))\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.ObjectProperty))\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.DatatypeProperty))\n",
    "\n",
    "    return extracted_graph\n",
    "\n",
    "\n",
    "rbox_graph = Graph()\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.DatatypeProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "\n",
    "serialize(rbox_graph, dataset_path / \"rbox\" / \"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_graph = Graph()\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    for s,p,o in onto_graph.triples((c, None, None)):\n",
    "        if p == RDFS.subClassOf:\n",
    "            taxonomy_graph.add((s,p,o))\n",
    "            if isinstance(o, BNode):\n",
    "                taxonomy_graph += extract_description(onto_graph, o)\n",
    "\n",
    "serialize(taxonomy_graph, dataset_path / \"tbox\" / \"taxonomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_graph = Graph()\n",
    "\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    if not isinstance(c, BNode):\n",
    "        for s,p,o in onto_graph.triples((c, None, None)):\n",
    "            if p != RDFS.subClassOf:\n",
    "                \n",
    "                schema_graph.add((s,p,o))\n",
    "\n",
    "                for elem in onto_graph.objects(o, RDF.type):\n",
    "                    schema_graph.add((o, RDF.type, elem))\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    print(f\"Found BNODE in Triple {s, p, o}\")\n",
    "                    schema_graph += extract_description(onto_graph, o)\n",
    "            \n",
    "\n",
    "serialize(schema_graph, dataset_path / \"tbox\" / \"schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03922d4f",
   "metadata": {},
   "source": [
    "# Final Ontology and Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/navis/robot/robot merge \\\n",
    "--input  {dataset_path / \"ontology.owl\"} \\\n",
    "--input  {dataset_path / \"abox\" / \"individuals.owl\"} \\\n",
    "--input {dataset_path / \"abox\" / \"triples.nt\"} \\\n",
    "--input {dataset_path / \"abox\" / \"class_assertions.owl\"} \\\n",
    "--output {dataset_path / \"knowledge_graph.owl\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
