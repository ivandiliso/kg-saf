{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc696eda",
   "metadata": {},
   "source": [
    "# **Return of the Schema** for *DBpedia*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1f207",
   "metadata": {},
   "source": [
    "## Path Definition Basic Elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d3d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, RDFS, OWL, Namespace\n",
    "from urllib.parse import quote\n",
    "from rdflib.namespace import split_uri\n",
    "from rdflib.term import URIRef\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "\n",
    "def serialize(graph, path):\n",
    "    graph.serialize(path.with_suffix(\".xml\"), format=\"xml\")\n",
    "    !/home/navis/robot/robot merge --input {path.with_suffix(\".xml\")} --output {path.with_suffix(\".owl\")}\n",
    "    path.with_suffix(\".xml\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee065469",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATERIALIZE = True\n",
    "DBPEDIA_RESOURCE = \"http://dbpedia.org/resource/\"\n",
    "DBPEDIA_ONTOLOGY = \"http://dbpedia.org/ontology/\"\n",
    "DATASET_NAME = \"DBPEDIA25-50K-C\"\n",
    "DATASET_NAME += f\"-{'MATERIALIZE' if MATERIALIZE else \"BASE\"}\"\n",
    "\n",
    "home_path = Path().cwd().absolute().parent.parent \n",
    "dataset_path = home_path / \"kgsaf_data\" / f\"{'materialize' if MATERIALIZE else \"base\"}\" / \"unpack\" / DATASET_NAME\n",
    "onto_path = home_path / \"kgsaf_data\" / \"ontologies\"/ \"unpack\" / \"DBPEDIA-2025\"\n",
    "\n",
    "print(\"Base Path\", home_path)\n",
    "print(\"Ontology\", onto_path)\n",
    "print(\"Dataset\", dataset_path)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "if MATERIALIZE:\n",
    "    print(\"Loading MATERIALIZED Ontology\")\n",
    "    onto_file = onto_path / \"dbpedia_repaired_materialized.owl\"\n",
    "else:\n",
    "    print(\"Loading BASE Ontology\")\n",
    "    onto_file = onto_path / \"dbpedia_repaired.owl\"\n",
    "\n",
    "print(\"\\tLoading Ontology\")\n",
    "\n",
    "dbpedia_ontology = Graph()\n",
    "dbpedia_ontology.parse(onto_file)\n",
    "\n",
    "print(\"\\tOntology Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpedia_class_assertions = Graph()\n",
    "dbpedia_class_assertions.parse(onto_path / \"dbpedia_abox_type.ttl\")\n",
    "\n",
    "print(\"Base Path\", home_path)\n",
    "print(\"Dataset\", dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fc2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILTIN_URI = {\n",
    "    URIRef(\"http://schema.org/Thing\"),\n",
    "    OWL.Thing,\n",
    "    OWL.Nothing,\n",
    "    OWL.NamedIndividual,\n",
    "    OWL.Class,\n",
    "    OWL.topObjectProperty,\n",
    "    OWL.bottomObjectProperty,\n",
    "    RDF.type,\n",
    "    RDFS.domain,\n",
    "    RDFS.range,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36736cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(graph, path):\n",
    "    graph.serialize(path.with_suffix(\".xml\"), format=\"xml\")\n",
    "    !/home/navis/robot/robot merge --input {path.with_suffix(\".xml\")} --output {path.with_suffix(\".owl\")}\n",
    "    path.with_suffix(\".xml\").unlink()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03536b2a",
   "metadata": {},
   "source": [
    "# ABOX Triple Cleaning\n",
    "\n",
    "Removal of triples with individuals that are also classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbe278",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples_legacy.nt\")\n",
    "\n",
    "individuals = set(data_triples.subjects()) | set(data_triples.objects())\n",
    "\n",
    "print(\"Len Individuals\", len(individuals))\n",
    "print(\"Num Triples:\", len(data_triples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_classes = set()\n",
    "\n",
    "for ind in individuals:\n",
    "    if (ind, RDF.type, OWL.Class) in dbpedia_ontology:\n",
    "        ind_classes.add(ind)\n",
    "\n",
    "print(\"Individuals that are Classes:\", len(ind_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a84d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpedia_obj_props = set(dbpedia_ontology.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI\n",
    "\n",
    "print(\"Valid Obj Props:\", len(dbpedia_obj_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da6191",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_invalid = 0\n",
    "with open(dataset_path / \"abox\" / \"triples.tsv\", \"w\") as out_file:\n",
    "    for s,p,o in data_triples:\n",
    "        if (s in ind_classes) or (o in ind_classes) or not(p in dbpedia_obj_props):\n",
    "            print(f\"INVALID Triple {s,p,o}\")\n",
    "            total_invalid += 1\n",
    "        else:\n",
    "            out_file.write(f\"{s}\\t{p}\\t{o}\\n\")\n",
    "\n",
    "print(f\"Found a total of {total_invalid} invalid triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "del individuals\n",
    "del ind_classes\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210863d",
   "metadata": {},
   "source": [
    "# Triples Cleaning and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples.splitting import CoverageSplitter\n",
    "import numpy as np\n",
    "from rdflib import Graph, OWL, Literal\n",
    "from rdflib.namespace import XSD    \n",
    "\n",
    "triples = TriplesFactory.from_path(dataset_path / \"abox\" / \"triples.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d04157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples.splitting import CoverageSplitter\n",
    "import numpy as np\n",
    "\n",
    "MIN_TRIPLES_RELATION = 2\n",
    "\n",
    "rels, counts = np.unique(triples.mapped_triples[:, 1], return_counts=True)\n",
    "rel_counts = dict(zip(rels, counts))\n",
    "\n",
    "keep_relations = [r for r, c in rel_counts.items() if c >= MIN_TRIPLES_RELATION]\n",
    "\n",
    "triples_clean = triples.new_with_restriction(\n",
    "    relations=keep_relations\n",
    ")\n",
    "\n",
    "print(\"Original triples:\", triples.num_triples)\n",
    "print(\"Cleaned triples:\", triples_clean.num_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1577ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mappings = {v:k for k,v in triples_clean.entity_id_to_label.items()}\n",
    "relation_mappings = {v:k for k,v in triples_clean.relation_id_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = triples_clean.split(\n",
    "    ratios=[0.84, 0.08, 0.08],\n",
    "    random_state=42,\n",
    "    method=CoverageSplitter(),      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe17b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=train.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "valid_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=valid.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "test_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=test.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples.leakage import unleak\n",
    "\n",
    "train_unleak, valid_unleak, test_unleak = unleak(\n",
    "    train_clean,\n",
    "    *[valid_clean, test_clean],\n",
    "    n=None,\n",
    "    minimum_frequency=0.97\n",
    "    )\n",
    "\n",
    "print(train_unleak)\n",
    "print(test_unleak)\n",
    "print(valid_unleak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ce6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    (dataset_path / \"abox/splits/train\", train_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/valid\", valid_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/test\", test_unleak.triples)\n",
    "]\n",
    "\n",
    "\n",
    "for path, split in targets:\n",
    "    out_graph = Graph()\n",
    "    for triple in split:\n",
    "        s = URIRef(triple[0].strip())\n",
    "        p = URIRef(triple[1].strip())\n",
    "        o = URIRef(triple[2].strip())\n",
    "        out_graph.add((URIRef(s), URIRef(p), URIRef(o)))\n",
    "\n",
    "    out_graph.serialize(path.with_suffix(\".nt\"), format=\"nt\")\n",
    "\n",
    "!cat {dataset_path}/abox/splits/*.nt > {dataset_path}/abox/triples.nt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741220b6",
   "metadata": {},
   "source": [
    "# ABOX Individuals and Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "individuals = set(data_triples.subjects()) | set(data_triples.objects())\n",
    "\n",
    "print(\"Len Individuals\", len(individuals))\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec37c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    out_graph.add((ind, RDF.type, OWL.NamedIndividual))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"individuals\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaad660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_localname(uri: URIRef) -> URIRef:\n",
    "    \"\"\"Return a new URIRef with the local name capitalized.\"\"\"\n",
    "    uri_str = str(uri)\n",
    "    \n",
    "    if \"#\" in uri_str:\n",
    "        ns, ln = uri_str.rsplit(\"#\", 1)\n",
    "        return URIRef(f\"{ns}#{ln[0].upper() + ln[1:]}\")\n",
    "    else:\n",
    "        ns, ln = uri_str.rsplit(\"/\", 1)\n",
    "        return URIRef(f\"{ns}/{ln[0].upper() + ln[1:]}\")\n",
    "\n",
    "\n",
    "out_graph = Graph()\n",
    "\n",
    "\n",
    "for ind in individuals:\n",
    "    for ca in  set(dbpedia_class_assertions.objects(ind, RDF.type)) - BUILTIN_URI:\n",
    "        ca_norm = capitalize_localname(ca)\n",
    "        if (ca, RDF.type, OWL.Class) in dbpedia_ontology:\n",
    "            out_graph.add((ind, RDF.type, ca_norm))\n",
    "        else:\n",
    "            print(f\"{ca} not a class\")\n",
    "\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_localname(uri: URIRef) -> URIRef:\n",
    "    \"\"\"Return a new URIRef with the local name capitalized.\"\"\"\n",
    "    uri_str = str(uri)\n",
    "    \n",
    "    if \"#\" in uri_str:\n",
    "        ns, ln = uri_str.rsplit(\"#\", 1)\n",
    "        return URIRef(f\"{ns}#{ln[0].upper() + ln[1:]}\")\n",
    "    else:\n",
    "        ns, ln = uri_str.rsplit(\"/\", 1)\n",
    "        return URIRef(f\"{ns}/{ln[0].upper() + ln[1:]}\")\n",
    "\n",
    "\n",
    "out_graph = Graph()\n",
    "\n",
    "\n",
    "for ind in individuals:\n",
    "    for ca in  set(dbpedia_class_assertions.objects(ind, RDF.type)) - BUILTIN_URI:\n",
    "        ca_norm = capitalize_localname(ca)\n",
    "        if (ca, RDF.type, OWL.Class) in dbpedia_ontology:\n",
    "            out_graph.add((ind, RDF.type, ca_norm))\n",
    "        else:\n",
    "            print(f\"{ca} not a class\")\n",
    "\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"unreasoned_class_assertions\")\n",
    "del out_graph\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df005ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -Xmx16G -jar /home/navis/robot/robot.jar merge -vvv \\\n",
    "    --input {dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\"} \\\n",
    "    --input {home_path / \"enricher\" / \"ontologies\" / \"DBPEDIA\" / \"dbpedia_cleaned_reasoned.owl\"} \\\n",
    "    --output {dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb94a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = [\n",
    "    #\"SubClass\",\n",
    "    #\"EquivalentClass\",\n",
    "    #\"DisjointClasses\",\n",
    "    #\"DataPropertyCharacteristic\",\n",
    "    #\"EquivalentDataProperties\",\n",
    "    #\"SubDataProperty\",\n",
    "    \"ClassAssertion\",\n",
    "    #\"PropertyAssertion\",\n",
    "    #\"EquivalentObjectProperty\",\n",
    "    #\"InverseObjectProperties\",\n",
    "    #\"ObjectPropertyCharacteristic\",\n",
    "    #\"SubObjectProperty\",\n",
    "    #\"ObjectPropertyRange\",\n",
    "    #\"ObjectPropertyDomain\"\n",
    "]\n",
    "\n",
    "prop_string = \"\"\n",
    "for p in properties:\n",
    "    prop_string += \" \" + p\n",
    "\n",
    "\n",
    "!java -Xmx16G -jar /home/navis/robot/robot.jar reason -vvv \\\n",
    "  --reasoner HermiT \\\n",
    "  --create-new-ontology true \\\n",
    "  --input {dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\"} \\\n",
    "  --output {dataset_path / \"abox\" / \"inferred_class_assertions.owl\"} \\\n",
    "  --axiom-generators \"{prop_string}\" \\\n",
    "  --remove-redundant-subclass-axioms false \\\n",
    "  --exclude-tautologies structural \\\n",
    "  --include-indirect true \\\n",
    "  -D {dataset_path / \"class_assertions_debug.owl\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = Graph()\n",
    "ca.parse(dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\")\n",
    "ca.parse(dataset_path / \"abox\" / \"inferred_class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for s,p,o in ca.triples((None, RDF.type, None)):\n",
    "    if s in individuals:\n",
    "        out_graph.add((s,p,o))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_path / \"abox\" / \"inferred_class_assertions.owl\").unlink()\n",
    "(dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\").unlink()\n",
    "(dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab44efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(out_graph)\n",
    "del(ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6959a9",
   "metadata": {},
   "source": [
    "# RBOX Roles Definition and Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "class_assertions = Graph()\n",
    "class_assertions.parse(dataset_path / \"abox\" / \"class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611274f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_obj_props = set(data_triples.predicates())\n",
    "print(\"Seed Object Properties\", len(seed_obj_props))\n",
    "\n",
    "seed_classes =  set(class_assertions.subjects(RDF.type, OWL.Class))\n",
    "print(\"Seed Classes\", len(seed_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, BNode, RDF, RDFS, OWL\n",
    "\n",
    "BUILTIN_URI = {\n",
    "    URIRef(\"http://schema.org/Thing\"),\n",
    "    OWL.Thing,\n",
    "    OWL.Nothing,\n",
    "    OWL.NamedIndividual,\n",
    "    OWL.Class,\n",
    "    OWL.topObjectProperty,\n",
    "    OWL.bottomObjectProperty,\n",
    "    RDF.type,\n",
    "    RDFS.domain,\n",
    "    RDFS.range,\n",
    "    OWL.ObjectProperty,\n",
    "    OWL.Restriction,\n",
    "    OWL.DatatypeProperty,\n",
    "    RDFS.Literal\n",
    "}\n",
    "\n",
    "removal = [\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasDerivedFrom\"),\n",
    "    RDFS.isDefinedBy,\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasInfluencedBy\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def extract_recursive_description(graph: Graph, elements: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = set(elements)\n",
    "    processed = set()\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "        \n",
    "    return extracted_graph\n",
    "\n",
    "out_graph = extract_recursive_description(dbpedia_ontology, seed_classes | seed_obj_props)\n",
    "\n",
    "serialize(out_graph, dataset_path / \"ontology\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52861f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import BNode\n",
    "\n",
    "onto_graph = Graph()\n",
    "onto_graph.parse(dataset_path / \"ontology.owl\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_description(graph: Graph, elem: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = {elem}\n",
    "    processed = set()\n",
    "\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.Class))\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.ObjectProperty))\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.DatatypeProperty))\n",
    "\n",
    "    return extracted_graph\n",
    "\n",
    "\n",
    "rbox_graph = Graph()\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.DatatypeProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "\n",
    "serialize(rbox_graph, dataset_path / \"rbox\" / \"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_graph = Graph()\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    for s,p,o in onto_graph.triples((c, None, None)):\n",
    "        if p == RDFS.subClassOf:\n",
    "            taxonomy_graph.add((s,p,o))\n",
    "            if isinstance(o, BNode):\n",
    "                taxonomy_graph += extract_description(onto_graph, o)\n",
    "\n",
    "serialize(taxonomy_graph, dataset_path / \"tbox\" / \"taxonomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59e98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_graph = Graph()\n",
    "\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    if not isinstance(c, BNode):\n",
    "        for s,p,o in onto_graph.triples((c, None, None)):\n",
    "            if p != RDFS.subClassOf:\n",
    "                \n",
    "                schema_graph.add((s,p,o))\n",
    "\n",
    "                for elem in onto_graph.objects(o, RDF.type):\n",
    "                    schema_graph.add((o, RDF.type, elem))\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    print(f\"Found BNODE in Triple {s, p, o}\")\n",
    "                    schema_graph += extract_description(onto_graph, o)\n",
    "            \n",
    "\n",
    "serialize(schema_graph, dataset_path / \"tbox\" / \"schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dbc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del out_graph\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03922d4f",
   "metadata": {},
   "source": [
    "# Final Ontology and Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/navis/robot/robot merge \\\n",
    "--input  {dataset_path / \"ontology.owl\"} \\\n",
    "--input  {dataset_path / \"abox\" / \"individuals.owl\"} \\\n",
    "--input {dataset_path / \"abox\" / \"triples.nt\"} \\\n",
    "--input {dataset_path / \"abox\" / \"class_assertions.owl\"} \\\n",
    "--output {dataset_path / \"knowledge_graph.owl\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
