{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc696eda",
   "metadata": {},
   "source": [
    "# **Return of the Schema** for *WHOW* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1f207",
   "metadata": {},
   "source": [
    "## Path Definition Basic Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae5af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, RDFS, OWL, Namespace\n",
    "from urllib.parse import quote\n",
    "from rdflib.namespace import split_uri\n",
    "from rdflib.term import URIRef\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import csv\n",
    "import ast\n",
    "import json\n",
    "\n",
    "def serialize(graph, path):\n",
    "    graph.serialize(path.with_suffix(\".xml\"), format=\"xml\")\n",
    "    !/home/navis/robot/robot merge --input {path.with_suffix(\".xml\")} --output {path.with_suffix(\".owl\")}\n",
    "    path.with_suffix(\".xml\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00641d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATERIALIZE = True\n",
    "DBPEDIA_RESOURCE = \"http://dbpedia.org/resource/\"\n",
    "DBPEDIA_ONTOLOGY = \"http://dbpedia.org/ontology/\"\n",
    "DATASET_NAME = \"WHOW-5\"\n",
    "DATASET_NAME += f\"-{'MATERIALIZE' if MATERIALIZE else \"BASE\"}\"\n",
    "\n",
    "home_path = Path().cwd().absolute().parent.parent \n",
    "dataset_path = home_path / \"kgsaf_data\" / f\"{'materialize' if MATERIALIZE else \"base\"}\" / \"unpack\" / DATASET_NAME\n",
    "onto_path = home_path / \"kgsaf_data\" / \"ontologies\"/ \"unpack\" / \"WHOW\"\n",
    "\n",
    "print(\"Base Path\", home_path)\n",
    "print(\"Ontology\", onto_path)\n",
    "print(\"Dataset\", dataset_path)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "if MATERIALIZE:\n",
    "    print(\"Loading MATERIALIZED Ontology\")\n",
    "    onto_file = onto_path / \"whow_merged_repaired_materialized.owl\"\n",
    "else:\n",
    "    print(\"Loading BASE Ontology\")\n",
    "    onto_file = onto_path / \"whow_merged_repaired.owl\"\n",
    "\n",
    "print(\"\\tLoading Ontology\")\n",
    "\n",
    "whow_ontology = Graph()\n",
    "whow_ontology.parse(onto_file, format=\"xml\")\n",
    "\n",
    "print(\"\\tOntology Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03536b2a",
   "metadata": {},
   "source": [
    "# Triple Cleaning and Splitting, Deprecated Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbe278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples.splitting import CoverageSplitter\n",
    "import numpy as np\n",
    "from rdflib import Graph, OWL, Literal\n",
    "from rdflib.namespace import XSD    \n",
    "\n",
    "triples = TriplesFactory.from_path(onto_path / \"WHOW_ABOX\" / \"filtered5_giorno.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_obj_props = {str(s) for s in set(whow_ontology.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI }\n",
    "\n",
    "print(len(real_obj_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_props = set(triples.relation_id_to_label.values())\n",
    "print(len(obj_props))\n",
    "print(obj_props)\n",
    "\n",
    "reals = real_obj_props & obj_props\n",
    "\n",
    "print(len(reals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1036ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykeen\n",
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.triples.splitting import CoverageSplitter\n",
    "import numpy as np\n",
    "\n",
    "MIN_TRIPLES_RELATION = 5\n",
    "\n",
    "\n",
    "\n",
    "rels, counts = np.unique(triples.mapped_triples[:, 1], return_counts=True)\n",
    "rel_counts = dict(zip(rels, counts))\n",
    "\n",
    "keep_relations = [r for r, c in rel_counts.items() if c >= MIN_TRIPLES_RELATION]\n",
    "\n",
    "triples_clean = triples.new_with_restriction(\n",
    "    relations=keep_relations\n",
    ")\n",
    "\n",
    "print(\"Original triples:\", triples.num_triples)\n",
    "print(\"Cleaned triples:\", triples_clean.num_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248e94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_mappings = {v:k for k,v in triples_clean.entity_id_to_label.items()}\n",
    "relation_mappings = {v:k for k,v in triples_clean.relation_id_to_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b48b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = triples_clean.split(\n",
    "    ratios=[0.7, 0.1, 0.2],\n",
    "    random_state=42,\n",
    "    method=CoverageSplitter(),      \n",
    ")\n",
    "\n",
    "\n",
    "train_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=train.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "valid_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=valid.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "test_clean = TriplesFactory.from_labeled_triples(\n",
    "    triples=test.triples,\n",
    "    entity_to_id=entity_mappings,\n",
    "    relation_to_id=relation_mappings\n",
    ")\n",
    "\n",
    "print(train_clean)\n",
    "print(test_clean)\n",
    "print(valid_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3448bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples.leakage import unleak\n",
    "\n",
    "train_unleak, valid_unleak, test_unleak = unleak(\n",
    "    train_clean,\n",
    "    *[valid_clean, test_clean],\n",
    "    n=None,\n",
    "    minimum_frequency=0.97\n",
    "    )\n",
    "\n",
    "print(train_unleak)\n",
    "print(test_unleak)\n",
    "print(valid_unleak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20021068",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_path / \"abox\" / \"splits\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "targets = [\n",
    "    (dataset_path / \"abox/splits/train\", train_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/valid\", valid_unleak.triples),\n",
    "    (dataset_path / \"abox/splits/test\", test_unleak.triples)\n",
    "]\n",
    "\n",
    "\n",
    "for path, split in targets:\n",
    "    out_graph = Graph()\n",
    "    for triple in split:\n",
    "        s = URIRef(triple[0].strip())\n",
    "        p = URIRef(triple[1].strip())\n",
    "        o = URIRef(triple[2].strip())\n",
    "        out_graph.add((URIRef(s), URIRef(p), URIRef(o)))\n",
    "\n",
    "    out_graph.serialize(path.with_suffix(\".nt\"), format=\"nt\")\n",
    "\n",
    "!cat {dataset_path}/abox/splits/*.nt > {dataset_path}/abox/triples.nt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741220b6",
   "metadata": {},
   "source": [
    "# [R] ABOX Individuals and Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c5092",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "individuals = set(data_triples.subjects()) | set(data_triples.objects())\n",
    "\n",
    "print(\"Len Individuals\", len(individuals))\n",
    "del data_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec37c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    out_graph.add((ind, RDF.type, OWL.NamedIndividual))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"individuals\")\n",
    "del out_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec97e98",
   "metadata": {},
   "source": [
    "### [BASE] RDF Lib Class Assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d36f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "with open(onto_path / \"WHOW_ABOX\" / \"class_assertions_filtered5.json\", \"r\") as ca_file:\n",
    "    ca_data = json.load(ca_file)\n",
    "    for key in ca_data.keys():\n",
    "        ind = URIRef(key.strip())\n",
    "        for c in ca_data[key]:\n",
    "            cls = URIRef(c.strip())\n",
    "            if (cls, RDF.type, OWL.Class) in whow_ontology:\n",
    "                out_graph.add((ind, RDF.type, cls))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2f496",
   "metadata": {},
   "source": [
    "#### [REASONED] Reasoner Class Assertions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "with open(onto_path / \"WHOW_ABOX\" / \"class_assertions_filtered5.json\", \"r\") as ca_file:\n",
    "    ca_data = json.load(ca_file)\n",
    "    for key in ca_data.keys():\n",
    "        ind = URIRef(key.strip())\n",
    "        for c in ca_data[key]:\n",
    "            cls = URIRef(c.strip())\n",
    "            if (cls, RDF.type, OWL.Class) in whow_ontology:\n",
    "                out_graph.add((ind, RDF.type, cls))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"unreasoned_class_assertions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df005ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!java -Xmx16G -jar /home/navis/robot/robot.jar merge -vvv \\\n",
    "    --input {dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\"} \\\n",
    "    --input {dataset_path / \"abox\" / \"individuals.owl\"} \\\n",
    "    --input {dataset_path / \"abox\" / \"triples.nt\"} \\\n",
    "    --input {apulia_path / \"apulia_travel_merged_materialized.owl\"} \\\n",
    "    --output {dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\"}\n",
    "\n",
    "\n",
    "!java -Xmx16G -jar /home/navis/robot/robot.jar reason -vvv \\\n",
    "  --reasoner HermiT \\\n",
    "  --create-new-ontology true \\\n",
    "  --input {dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\"} \\\n",
    "  --output {dataset_path / \"abox\" / \"inferred_class_assertions.owl\"} \\\n",
    "  --axiom-generators \"ClassAssertion\" \\\n",
    "  --remove-redundant-subclass-axioms false \\\n",
    "  --exclude-tautologies structural \\\n",
    "  --include-indirect true \\\n",
    "  -D {dataset_path / \"class_assertions_debug.owl\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = Graph()\n",
    "ca.parse(dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\")\n",
    "ca.parse(dataset_path / \"abox\" / \"inferred_class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb80d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    for o in set(ca.objects(ind, RDF.type)) - BUILTIN_URI:\n",
    "        out_graph.add((ind,RDF.type, o))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dataset_path / \"abox\" / \"inferred_class_assertions.owl\").unlink()\n",
    "(dataset_path / \"abox\" / \"unreasoned_class_assertions.owl\").unlink()\n",
    "(dataset_path / \"abox\" / \"intermediate_abox_tbox.owl\").unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab44efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(out_graph)\n",
    "del(ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c749e75",
   "metadata": {},
   "source": [
    "### [REASONED] Server Reasoned Class Assetions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_graph = Graph()\n",
    "ca_graph.parse(onto_path / \"WHOW_ABOX\" / \"server_reasoned_class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24102254",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_graph = Graph()\n",
    "\n",
    "for ind in individuals:\n",
    "    for o in set(ca_graph.objects(ind, RDF.type)) - BUILTIN_URI:\n",
    "        out_graph.add((ind,RDF.type, o))\n",
    "\n",
    "serialize(out_graph, dataset_path / \"abox\" / \"class_assertions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6959a9",
   "metadata": {},
   "source": [
    "# TBOX and RBOX Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_triples = Graph()\n",
    "data_triples.parse(dataset_path / \"abox\" / \"triples.nt\")\n",
    "\n",
    "class_assertions = Graph()\n",
    "class_assertions.parse(dataset_path / \"abox\" / \"class_assertions.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_obj_props = set(data_triples.predicates())\n",
    "print(\"Seed Object Properties\", len(seed_obj_props))\n",
    "\n",
    "seed_classes =  set(class_assertions.subjects(RDF.type, OWL.Class))\n",
    "print(\"Seed Classes\", len(seed_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8adbd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, URIRef, BNode, RDF, RDFS, OWL\n",
    "\n",
    "BUILTIN_URI = {\n",
    "    URIRef(\"http://schema.org/Thing\"),\n",
    "    OWL.Thing,\n",
    "    OWL.Nothing,\n",
    "    OWL.NamedIndividual,\n",
    "    OWL.Class,\n",
    "    OWL.topObjectProperty,\n",
    "    OWL.bottomObjectProperty,\n",
    "    RDF.type,\n",
    "    RDFS.domain,\n",
    "    RDFS.range,\n",
    "    OWL.ObjectProperty,\n",
    "    OWL.Restriction,\n",
    "    OWL.DatatypeProperty,\n",
    "    RDFS.Literal\n",
    "}\n",
    "\n",
    "removal = [\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasDerivedFrom\"),\n",
    "    RDFS.isDefinedBy,\n",
    "    URIRef(\"http://www.w3.org/ns/prov#wasInfluencedBy\")\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def extract_recursive_description(graph: Graph, elements: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = set(elements)\n",
    "    processed = set()\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "        \n",
    "    return extracted_graph\n",
    "\n",
    "out_graph = extract_recursive_description(whow_ontology, seed_classes | seed_obj_props)\n",
    "\n",
    "serialize(out_graph, dataset_path / \"ontology\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import BNode\n",
    "\n",
    "onto_graph = Graph()\n",
    "onto_graph.parse(dataset_path / \"ontology.owl\")\n",
    "\n",
    "\n",
    "\n",
    "def extract_description(graph: Graph, elem: URIRef) -> Graph:\n",
    "\n",
    "    extracted_graph = Graph()\n",
    "    elem_to_process = {elem}\n",
    "    processed = set()\n",
    "\n",
    "\n",
    "    while elem_to_process:\n",
    "\n",
    "        e = elem_to_process.pop()\n",
    "        processed.add(e)\n",
    "\n",
    "        print(f\"Processing {e}\")\n",
    "\n",
    "        for s,p,o in graph.triples((e, None, None)):\n",
    "            extracted_graph.add((s,p,o))\n",
    "\n",
    "            if (o not in BUILTIN_URI) and (o not in processed):\n",
    "                if isinstance(o, BNode):\n",
    "                    elem_to_process.add(o)\n",
    "\n",
    "                if (o, RDF.type, OWL.Class) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.Class))\n",
    "\n",
    "                if (o, RDF.type, OWL.ObjectProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.ObjectProperty))\n",
    "\n",
    "                if (o, RDF.type, OWL.DatatypeProperty) in graph:\n",
    "                    extracted_graph.add((o, RDF.type, OWL.DatatypeProperty))\n",
    "\n",
    "    return extracted_graph\n",
    "\n",
    "\n",
    "rbox_graph = Graph()\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.ObjectProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "for prop in set(onto_graph.subjects(RDF.type, OWL.DatatypeProperty)) - BUILTIN_URI:\n",
    "    rbox_graph += extract_description(onto_graph, prop)\n",
    "\n",
    "\n",
    "serialize(rbox_graph, dataset_path / \"rbox\" / \"roles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_graph = Graph()\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    for s,p,o in onto_graph.triples((c, None, None)):\n",
    "        if p == RDFS.subClassOf:\n",
    "            taxonomy_graph.add((s,p,o))\n",
    "            if isinstance(o, BNode):\n",
    "                taxonomy_graph += extract_description(onto_graph, o)\n",
    "\n",
    "serialize(taxonomy_graph, dataset_path / \"tbox\" / \"taxonomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_graph = Graph()\n",
    "\n",
    "\n",
    "for c in set(onto_graph.subjects(RDF.type, OWL.Class)) - BUILTIN_URI:\n",
    "    if not isinstance(c, BNode):\n",
    "        for s,p,o in onto_graph.triples((c, None, None)):\n",
    "            if p != RDFS.subClassOf:\n",
    "                \n",
    "                schema_graph.add((s,p,o))\n",
    "\n",
    "                for elem in onto_graph.objects(o, RDF.type):\n",
    "                    schema_graph.add((o, RDF.type, elem))\n",
    "\n",
    "                if isinstance(o, BNode):\n",
    "                    print(f\"Found BNODE in Triple {s, p, o}\")\n",
    "                    schema_graph += extract_description(onto_graph, o)\n",
    "            \n",
    "\n",
    "serialize(schema_graph, dataset_path / \"tbox\" / \"schema\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03922d4f",
   "metadata": {},
   "source": [
    "# Final Ontology and Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b73d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/navis/robot/robot merge \\\n",
    "--input  {dataset_path / \"ontology.owl\"} \\\n",
    "--input  {dataset_path / \"abox\" / \"individuals.owl\"} \\\n",
    "--input {dataset_path / \"abox\" / \"triples.nt\"} \\\n",
    "--input {dataset_path / \"abox\" / \"class_assertions.owl\"} \\\n",
    "--output {dataset_path / \"knowledge_graph.owl\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
