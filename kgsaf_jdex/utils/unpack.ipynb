{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent.parent))\n",
    "\n",
    "import shutil\n",
    "\n",
    "from rdflib import Graph\n",
    "\n",
    "import kgsaf_jdex.utils.conventions.paths as pc\n",
    "from kgsaf_jdex.utils.conversion import OWLConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a69990",
   "metadata": {},
   "source": [
    "# UNZIP Compressed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0295a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = Path.cwd().parent.parent.resolve()\n",
    "data_path = home_path / \"kgsaf_data\" / \"datasets\"\n",
    "\n",
    "for d_type in [data_path / \"base\", data_path / \"materialize\"]:\n",
    "    print(f\"Unpacking Datasets in {d_type}\")\n",
    "    (d_type / \"unpack\").mkdir(exist_ok=True, parents=True)\n",
    "    for elem in d_type.iterdir():\n",
    "        if elem.is_file():\n",
    "            print(f\"\\tUnpacking Dataset {elem.name}\")\n",
    "            target_folder = d_type / \"unpack\" / elem.stem\n",
    "\n",
    "            if target_folder.exists():\n",
    "                shutil.rmtree(target_folder)\n",
    "\n",
    "            shutil.unpack_archive(str(elem), str(target_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69415da",
   "metadata": {},
   "source": [
    "# UNZIP Compressed Ontologies (Schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff012af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = Path.cwd().parent.parent.resolve()\n",
    "data_path = home_path / \"kgsaf_data\" / \"ontologies\"\n",
    "\n",
    "\n",
    "print(f\"Unpacking Ontologies in {data_path}\")\n",
    "(data_path / \"unpack\").mkdir(exist_ok=True, parents=True)\n",
    "target_folder = data_path / \"unpack\" \n",
    "\n",
    "for elem in data_path.iterdir():\n",
    "    if elem.is_file():\n",
    "            print(f\"\\tUnpacking Ontology {elem.name}\")\n",
    "            \n",
    "            if (target_folder / elem.stem).exists():\n",
    "                shutil.rmtree(target_folder)\n",
    "\n",
    "            shutil.unpack_archive(str(elem), str(target_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980136a7",
   "metadata": {},
   "source": [
    "# Object Property Assertion Re-Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b837fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = Path.cwd().parent.parent.resolve()\n",
    "data_path = home_path / \"kgsaf_data\" / \"datasets\"\n",
    "\n",
    "for d_type in [data_path / \"base\" / \"unpack\", data_path / \"materialize\" / \"unpack\"]:\n",
    "    print(f\"Merging Object Assertions for Datasets in {d_type}\")\n",
    "    for data_folder in d_type.iterdir():\n",
    "        if data_folder.is_dir():\n",
    "            print(f\"\\t Merging Dataset {data_folder.name}\")\n",
    "            !cat {data_folder}/abox/splits/*.nt > {data_folder}/abox/obj_prop_assertions.nt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134032ef",
   "metadata": {},
   "source": [
    "# Full Knowledge Graph Re-Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_path = \"/home/navis/robot/robot\"\n",
    "home_path = Path.cwd().parent.parent.resolve()\n",
    "data_path = home_path / \"kgsaf_data\" / \"datasets\"\n",
    "\n",
    "for d_type in [data_path / \"base\" / \"unpack\", data_path / \"materialize\" / \"unpack\"]:\n",
    "    print(f\"Merging Full KG for Datasets in {d_type}\")\n",
    "    for data_folder in d_type.iterdir():\n",
    "        if data_folder.is_dir():\n",
    "            print(f\"\\t Merging Dataset {data_folder.name}\")\n",
    "            !{robot_path} merge \\\n",
    "            --input {data_folder / \"ontology.owl\"} \\\n",
    "            --input {data_folder / \"abox\" / \"individuals.owl\"} \\\n",
    "            --input {data_folder / \"abox\" / \"obj_prop_assertions.nt\"} \\\n",
    "            --input {data_folder / \"abox\" / \"class_assertions.owl\"} \\\n",
    "            --output {data_folder / \"knowledge_graph.owl\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3300e",
   "metadata": {},
   "source": [
    "# NTriples to PyKEEN TSV Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSVConverter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "    ):\n",
    "\n",
    "        self.p_data = dict()\n",
    "        self.base_path = Path(path).resolve().absolute()\n",
    "\n",
    "    def convert(\n",
    "        self,\n",
    "        triples: bool = True,\n",
    "        splits: bool = True,\n",
    "    ):\n",
    "\n",
    "        if triples:\n",
    "            self.p_data[\"triples\"] = (\n",
    "                self.preprocess_triples(self.base_path / \"abox/obj_prop_assertions.nt\"),\n",
    "                self.base_path / \"abox/obj_prop_assertions.tsv\",\n",
    "            )\n",
    "\n",
    "        if splits:\n",
    "            self.p_data[\"train\"] = (\n",
    "                self.preprocess_triples(self.base_path / pc.RDF_TRAIN),\n",
    "                self.base_path / pc.TRAIN,\n",
    "            )\n",
    "            self.p_data[\"test\"] = (\n",
    "                self.preprocess_triples(self.base_path / pc.RDF_TEST),\n",
    "                self.base_path / pc.TEST,\n",
    "            )\n",
    "            self.p_data[\"valid\"] = (\n",
    "                self.preprocess_triples(self.base_path / pc.RDF_VALID),\n",
    "                self.base_path / pc.VALID,\n",
    "            )\n",
    "\n",
    "\n",
    "    def serialize(self):\n",
    "        for key, values in self.p_data.items():\n",
    "            obj = values[0]\n",
    "            path = values[1]\n",
    "\n",
    "            with open(path, \"w\") as f:\n",
    "                if key in [\"triples\", \"train\", \"valid\", \"test\"]:\n",
    "                    f.write(obj)\n",
    "\n",
    "    def preprocess_triples(self, path):\n",
    "        triples = Graph()\n",
    "        triples.parse(path)\n",
    "        out_str = \"\"\n",
    "        for s, p, o in triples:\n",
    "            out_str += f\"{str(s)}\\t{str(p)}\\t{str(o)}\\n\"\n",
    "        return out_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd35c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot_path = \"/home/navis/robot/robot\"\n",
    "home_path = Path.cwd().parent.parent.resolve()\n",
    "data_path = home_path / \"kgsaf_data\" / \"datasets\"\n",
    "\n",
    "for d_type in [data_path / \"base\" / \"unpack\", data_path / \"materialize\" / \"unpack\"]:\n",
    "    print(f\"Converting NTriples Datasets in {d_type}\")\n",
    "    for data_folder in d_type.iterdir():\n",
    "        if data_folder.is_dir():\n",
    "            print(f\"\\t Converting Dataset {data_folder.name}\")\n",
    "            processor = TSVConverter(data_folder)\n",
    "            processor.convert()\n",
    "            processor.serialize()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87f7d13",
   "metadata": {},
   "source": [
    "# JSON OWL Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = Path.cwd().parent.parent.resolve()\n",
    "data_path = home_path / \"kgsaf_data\" / \"datasets\"\n",
    "\n",
    "for d_type in [data_path / \"base\" / \"unpack\", data_path / \"materialize\" / \"unpack\"]:\n",
    "    print(f\"Conversion to JSON for Datasets in {d_type}\")\n",
    "    for data_folder in d_type.iterdir():\n",
    "        if data_folder.is_dir():\n",
    "            print(f\"\\tProcessing Dataset {data_folder.name}\")\n",
    "            processor = OWLConverter(data_folder)\n",
    "            processor.preprocess(verbose=False)\n",
    "            processor.serialize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
